{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823d8f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘data/words’: File exists\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://git.io/J0fjL -O IAM_Words.zip \n",
    "!unzip -qq IAM_Words.zip \n",
    "\n",
    "!mkdir data \n",
    "!mkdir data/words \n",
    "!tar -xf IAM_Words/words.tgz -C data/words \n",
    "!mv IAM_Words/words.txt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ebb038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--- words.txt ---------------------------------------------------------------#\r\n",
      "#\r\n",
      "# iam database word information\r\n",
      "#\r\n",
      "# format: a01-000u-00-00 ok 154 1 408 768 27 51 AT A\r\n",
      "#\r\n",
      "#     a01-000u-00-00  -> word id for line 00 in form a01-000u\r\n",
      "#     ok              -> result of word segmentation\r\n",
      "#                            ok: word was correctly\r\n",
      "#                            er: segmentation of word can be bad\r\n",
      "#\r\n",
      "#     154             -> graylevel to binarize the line containing this word\r\n",
      "#     1               -> number of components for this word\r\n",
      "#     408 768 27 51   -> bounding box around this word in x,y,w,h format\r\n",
      "#     AT              -> the grammatical tag for this word, see the\r\n",
      "#                        file tagset.txt for an explanation\r\n",
      "#     A               -> the transcription for this word\r\n",
      "#\r\n"
     ]
    }
   ],
   "source": [
    "!head -18 data/words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3233ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import optuna\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "# hiding tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf1aff",
   "metadata": {},
   "source": [
    "# Data Splitting\n",
    "\n",
    "- We also remove any images that are labeled \"err\"\n",
    "- 80/10/10 split for training, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5d4501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 86810\n",
      "Total validation samples: 4823\n",
      "Total test samples: 4823\n"
     ]
    }
   ],
   "source": [
    "base_path = \"data\"\n",
    "words_list = []\n",
    "\n",
    "words = open(f\"{base_path}/words.txt\", \"r\").readlines()\n",
    "for line in words:\n",
    "    if line[0] == \"#\":\n",
    "        continue\n",
    "    if line.split(\" \")[1] != \"err\":  # We don't need to deal with errored entries.\n",
    "        words_list.append(line)\n",
    "\n",
    "np.random.shuffle(words_list)\n",
    "\n",
    "split_idx = int(0.9 * len(words_list))\n",
    "train_samples = words_list[:split_idx]\n",
    "test_samples = words_list[split_idx:]\n",
    "\n",
    "val_split_idx = int(0.5 * len(test_samples))\n",
    "validation_samples = test_samples[:val_split_idx]\n",
    "test_samples = test_samples[val_split_idx:]\n",
    "\n",
    "# make sure they all add up\n",
    "assert len(words_list) == len(train_samples) + len(validation_samples) + len(\n",
    "    test_samples\n",
    ")\n",
    "\n",
    "print(f\"Total training samples: {len(train_samples)}\")\n",
    "print(f\"Total validation samples: {len(validation_samples)}\")\n",
    "print(f\"Total test samples: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3971a999",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- Cleaning the data label that came from the words.txt file\n",
    "- Building the vocabulary of characters (from training data only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f5e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length:  21\n",
      "Vocab size:  78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sure',\n",
       " 'he',\n",
       " 'during',\n",
       " 'of',\n",
       " 'booty',\n",
       " 'gastronomy',\n",
       " 'boy',\n",
       " 'The',\n",
       " 'and',\n",
       " 'in']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_image_path = os.path.join(base_path, \"words\")\n",
    "\n",
    "def get_image_paths_and_labels(samples):\n",
    "    paths = []\n",
    "    corrected_samples = []\n",
    "    for (i, file_line) in enumerate(samples):\n",
    "        line_split = file_line.strip()\n",
    "        line_split = line_split.split(\" \")\n",
    "\n",
    "        # Each line split will have this format for the corresponding image:\n",
    "        # part1/part1-part2/part1-part2-part3.png\n",
    "        image_name = line_split[0]\n",
    "        partI = image_name.split(\"-\")[0]\n",
    "        partII = image_name.split(\"-\")[1]\n",
    "        img_path = os.path.join(\n",
    "            base_image_path, partI, partI + \"-\" + partII, image_name + \".png\"\n",
    "        )\n",
    "        if os.path.getsize(img_path):\n",
    "            paths.append(img_path)\n",
    "            corrected_samples.append(file_line.split(\"\\n\")[0])\n",
    "\n",
    "    return paths, corrected_samples\n",
    "\n",
    "\n",
    "train_img_paths, train_labels = get_image_paths_and_labels(train_samples)\n",
    "validation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples)\n",
    "test_img_paths, test_labels = get_image_paths_and_labels(test_samples)\n",
    "\n",
    "\"\"\"\n",
    "Then we prepare the ground-truth labels.\n",
    "\"\"\"\n",
    "\n",
    "# Find maximum length and the size of the vocabulary in the training data.\n",
    "train_labels_cleaned = []\n",
    "characters = set()\n",
    "max_len = 0\n",
    "\n",
    "for label in train_labels:\n",
    "    label = label.split(\" \")[-1].strip()\n",
    "    for char in label:\n",
    "        characters.add(char)\n",
    "\n",
    "    max_len = max(max_len, len(label))\n",
    "    train_labels_cleaned.append(label)\n",
    "\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "print(\"Maximum length: \", max_len)\n",
    "print(\"Vocab size: \", len(characters))\n",
    "train_labels_cleaned[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0670b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labels(labels):\n",
    "    cleaned_labels = []\n",
    "    for label in labels:\n",
    "        label = label.split(\" \")[-1].strip()\n",
    "        cleaned_labels.append(label)\n",
    "    return cleaned_labels\n",
    "\n",
    "validation_labels_cleaned = clean_labels(validation_labels)\n",
    "test_labels_cleaned = clean_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a77d0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Mapping characters to integers.\n",
    "char_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "\n",
    "# Mapping integers back to original characters.\n",
    "num_to_char = StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b32cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_free_resize(image, img_size):\n",
    "    \"\"\"\n",
    "    * Aspect ratio is preserved.\n",
    "    * Content of the images is not affected.\n",
    "    \"\"\"\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "\n",
    "    # Check tha amount of padding needed to be done.\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    # Only necessary if you want to do same amount of padding on both sides.\n",
    "    if pad_height % 2 != 0:\n",
    "        height = pad_height // 2\n",
    "        pad_height_top = height + 1\n",
    "        pad_height_bottom = height\n",
    "    else:\n",
    "        pad_height_top = pad_height_bottom = pad_height // 2\n",
    "\n",
    "    if pad_width % 2 != 0:\n",
    "        width = pad_width // 2\n",
    "        pad_width_left = width + 1\n",
    "        pad_width_right = width\n",
    "    else:\n",
    "        pad_width_left = pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(\n",
    "        image,\n",
    "        paddings=[\n",
    "            [pad_height_top, pad_height_bottom],\n",
    "            [pad_width_left, pad_width_right],\n",
    "            [0, 0],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe59701",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 30\n",
    "padding_token = 99\n",
    "image_width = 128\n",
    "image_height = 32\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, 1)\n",
    "    image = distortion_free_resize(image, img_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def vectorize_label(label):\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = max_len - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    return label\n",
    "\n",
    "\n",
    "def process_images_labels(image_path, label):\n",
    "    image = preprocess_image(image_path)\n",
    "    label = vectorize_label(label)\n",
    "    return {\"image\": image, \"label\": label}\n",
    "\n",
    "\n",
    "def prepare_dataset(image_paths, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n",
    "        process_images_labels, num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54c305",
   "metadata": {},
   "source": [
    "### Running All Data through Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fae38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_dataset(train_img_paths, train_labels_cleaned)\n",
    "validation_ds = prepare_dataset(validation_img_paths, validation_labels_cleaned)\n",
    "test_ds = prepare_dataset(test_img_paths, test_labels_cleaned)\n",
    "\n",
    "validation_images = []\n",
    "validation_labels = []\n",
    "\n",
    "for batch in validation_ds:\n",
    "    validation_images.append(batch[\"image\"])\n",
    "    validation_labels.append(batch[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13307b6a",
   "metadata": {},
   "source": [
    "# Optuna Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9fdd7",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bac9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions.\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def create_model(trial):\n",
    "    # Inputs to the model\n",
    "    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
    "\n",
    "    # First conv block.\n",
    "    conv1_activation = trial.suggest_categorical(\"conv1_activation\", [\"relu\", \"tanh\"])\n",
    "    conv1_kernal_size = trial.suggest_int(\"conv1_kernal_size\", 2, 4, step=1) \n",
    "    conv1_filters = trial.suggest_categorical(\"conv1_filters\", [16, 32, 64, 128])\n",
    "    x = keras.layers.Conv2D(\n",
    "        conv1_filters,\n",
    "        (conv1_kernal_size, conv1_kernal_size),\n",
    "        activation=conv1_activation,\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv1\",\n",
    "    )(input_img)\n",
    "    #max_pooling1 = trial.suggest_int(\"max_pooling1\", 1, 3, step=1)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "\n",
    "    # Second conv block.\n",
    "    conv2_activation = trial.suggest_categorical(\"conv2_activation\", [\"relu\", \"tanh\"])\n",
    "    conv2_filters = trial.suggest_categorical(\"conv1_filters\", [16, 32, 64, 128])\n",
    "    conv2_kernal_size = trial.suggest_int(\"conv2_kernal_size\", 2, 4)\n",
    "    x = keras.layers.Conv2D(\n",
    "        conv2_filters,\n",
    "        (conv2_kernal_size, conv2_kernal_size),\n",
    "        activation=conv2_activation,\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv2\",\n",
    "    )(x)\n",
    "    #max_pooling2 = trial.suggest_int(\"max_pooling2\", 1, 3, step=1)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "    new_shape = ((image_width // 4), (image_height // 4) * conv2_filters)\n",
    "    \n",
    "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "    \n",
    "    # Dense 1\n",
    "    dense1_activation = trial.suggest_categorical(\"dense1_activation\", [\"relu\", \"tanh\"])\n",
    "    dense1_filters = trial.suggest_categorical(\"dense1_filters\", [16, 32, 64, 128])\n",
    "    x = keras.layers.Dense(dense1_filters, \n",
    "                           activation=dense1_activation, \n",
    "                           name=\"dense1\")(x)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.15, 0.3)\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "    # RNNs.\n",
    "    \n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0.15, 0.3)\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(256, return_sequences=True, dropout=dropout1)\n",
    "    )(x)\n",
    "    \n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0.15, 0.3)\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(128, return_sequences=True, dropout=dropout2)\n",
    "    )(x)\n",
    "    \n",
    "    dropout3 = trial.suggest_float(\"dropout3\", 0.15, 0.3)\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(64, return_sequences=True, dropout=dropout3)\n",
    "    )(x)\n",
    "    \n",
    "\n",
    "    # +2 is to account for the two special tokens introduced by the CTC loss.\n",
    "    # The recommendation comes here: https://git.io/J0eXP.\n",
    "    \n",
    "    x = keras.layers.Dense(\n",
    "        len(char_to_num.get_vocabulary()) + 2, \n",
    "        activation=\"softmax\", \n",
    "        name=\"dense2\"\n",
    "    )(x)\n",
    "\n",
    "    # Add CTC layer for calculating CTC loss at each step.\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.models.Model(\n",
    "        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n",
    "    )\n",
    "    \n",
    "    optimizer = create_optimizer(trial)\n",
    "    model.compile(optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885799f",
   "metadata": {},
   "source": [
    "### Optuna Optimizer Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ebac2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial):\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"Adam\", \"SGD\"])\n",
    "    if optimizer_name == \"RMSprop\":\n",
    "        lrn_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        return keras.optimizers.RMSprop(learning_rate=lrn_rate)\n",
    "    elif optimizer_name == \"Adam\":\n",
    "        lrn_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        return keras.optimizers.Adam(learning_rate=lrn_rate)\n",
    "    else:\n",
    "        lrn_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        momentum = trial.suggest_float(\"sgd_opt_momentum\", 1e-5, 1e-1, log=True)\n",
    "        return keras.optimizers.SGD(learning_rate=lrn_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea3d66",
   "metadata": {},
   "source": [
    "### Running the Optuna Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 22:02:39,734]\u001b[0m A new study created in memory with name: no-name-55fe4810-6cb4-4b29-9c4b-7c8fa7ce2fec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2894/2894 [==============================] - 527s 180ms/step - loss: 14.7185 - val_loss: 13.3760\n",
      "Epoch 2/5\n",
      "2894/2894 [==============================] - 519s 179ms/step - loss: 12.4238 - val_loss: 12.3175\n",
      "Epoch 3/5\n",
      "2894/2894 [==============================] - 518s 179ms/step - loss: 11.6320 - val_loss: 11.8844\n",
      "Epoch 4/5\n",
      "2894/2894 [==============================] - 511s 177ms/step - loss: 10.9725 - val_loss: 11.3910\n",
      "Epoch 5/5\n",
      "2894/2894 [==============================] - 520s 180ms/step - loss: 10.3965 - val_loss: 10.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 22:46:17,088]\u001b[0m Trial 0 finished with value: 10.699230194091797 and parameters: {'conv1_activation': 'relu', 'conv1_kernal_size': 3, 'conv1_filters': 128, 'conv2_activation': 'tanh', 'conv2_kernal_size': 3, 'dense1_activation': 'relu', 'dense1_filters': 64, 'dropout': 0.2588281899202205, 'dropout1': 0.24851540784072856, 'dropout2': 0.1957974403031273, 'dropout3': 0.18997362822273584, 'optimizer': 'RMSprop', 'learning_rate': 4.37198621103679e-05}. Best is trial 0 with value: 10.699230194091797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.699230194091797\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "TRIALS = 50\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(train_ds,\n",
    "              validation_data=validation_ds,\n",
    "              epochs=EPOCHS)\n",
    "    score = model.evaluate(validation_ds, verbose=0)\n",
    "    print(score)\n",
    "    return score # loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=TRIALS)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Loss: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075ebd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 13:05:54,598]\u001b[0m A new study created in memory with name: no-name-9b99ab66-5ede-4d64-9271-0dc96be9fa64\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 544s 310ms/step - loss: 15.5815 - val_loss: 13.3036\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 549s 316ms/step - loss: 12.8515 - val_loss: 12.7443\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 552s 318ms/step - loss: 12.2655 - val_loss: 12.3496\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 539s 310ms/step - loss: 11.8203 - val_loss: 11.6212\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 534s 307ms/step - loss: 11.4394 - val_loss: 11.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 13:51:35,862]\u001b[0m Trial 0 finished with value: 11.282990455627441 and parameters: {'conv1_activation': 'tanh', 'conv1_kernal_size': 3, 'conv1_filters': 128, 'conv2_activation': 'relu', 'conv2_kernal_size': 2, 'dense1_activation': 'tanh', 'dense1_filters': 16, 'dropout': 0.17025617515768346, 'dropout1': 0.24395370077337075, 'dropout2': 0.1678819040278219, 'dropout3': 0.17606772863563322, 'optimizer': 'RMSprop', 'learning_rate': 5.4050553487620996e-05}. Best is trial 0 with value: 11.282990455627441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.282990455627441\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 539s 307ms/step - loss: 14.2184 - val_loss: 13.4656\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 521s 300ms/step - loss: 13.5250 - val_loss: 13.7039\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 532s 306ms/step - loss: 13.5878 - val_loss: 13.3960\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 535s 308ms/step - loss: 13.4566 - val_loss: 13.2686\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 533s 307ms/step - loss: 13.3534 - val_loss: 13.2564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 14:36:19,505]\u001b[0m Trial 1 finished with value: 13.2564058303833 and parameters: {'conv1_activation': 'tanh', 'conv1_kernal_size': 4, 'conv1_filters': 64, 'conv2_activation': 'tanh', 'conv2_kernal_size': 4, 'dense1_activation': 'tanh', 'dense1_filters': 32, 'dropout': 0.17573855933645482, 'dropout1': 0.293158037751315, 'dropout2': 0.1609573703067315, 'dropout3': 0.2512913196726221, 'optimizer': 'RMSprop', 'learning_rate': 0.014123409818068488}. Best is trial 0 with value: 11.282990455627441.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2564058303833\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 517s 295ms/step - loss: 12.1164 - val_loss: 9.6994\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 514s 296ms/step - loss: 8.8744 - val_loss: 8.0349\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 505s 291ms/step - loss: 7.6085 - val_loss: 7.0029\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 503s 290ms/step - loss: 6.6300 - val_loss: 6.0472\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 505s 291ms/step - loss: 5.8144 - val_loss: 5.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 15:19:07,503]\u001b[0m Trial 2 finished with value: 5.262175559997559 and parameters: {'conv1_activation': 'tanh', 'conv1_kernal_size': 3, 'conv1_filters': 16, 'conv2_activation': 'tanh', 'conv2_kernal_size': 4, 'dense1_activation': 'relu', 'dense1_filters': 64, 'dropout': 0.2016789077244987, 'dropout1': 0.21986319623915873, 'dropout2': 0.17333798751459284, 'dropout3': 0.24849332369425925, 'optimizer': 'RMSprop', 'learning_rate': 0.003403590295929654}. Best is trial 2 with value: 5.262175559997559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.262175559997559\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 572s 326ms/step - loss: 22.0367 - val_loss: 14.7341\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 557s 321ms/step - loss: 14.1172 - val_loss: 13.9957\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 572s 329ms/step - loss: 13.5663 - val_loss: 13.6022\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 563s 324ms/step - loss: 13.1897 - val_loss: 13.3762\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 561s 323ms/step - loss: 12.8836 - val_loss: 13.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 16:06:37,729]\u001b[0m Trial 3 finished with value: 13.154173851013184 and parameters: {'conv1_activation': 'tanh', 'conv1_kernal_size': 4, 'conv1_filters': 128, 'conv2_activation': 'tanh', 'conv2_kernal_size': 4, 'dense1_activation': 'tanh', 'dense1_filters': 32, 'dropout': 0.1855946587372339, 'dropout1': 0.15802481317927508, 'dropout2': 0.21579507510224188, 'dropout3': 0.28999575614135, 'optimizer': 'RMSprop', 'learning_rate': 1.2852743565354296e-05}. Best is trial 2 with value: 5.262175559997559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.154173851013184\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 541s 308ms/step - loss: 15.5334 - val_loss: 15.5338\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 531s 305ms/step - loss: 15.2420 - val_loss: 15.5252\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 531s 306ms/step - loss: 15.1981 - val_loss: 15.4815\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 532s 306ms/step - loss: 15.1750 - val_loss: 15.4227\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 545s 314ms/step - loss: 15.1684 - val_loss: 15.4149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 16:51:42,506]\u001b[0m Trial 4 finished with value: 15.414863586425781 and parameters: {'conv1_activation': 'tanh', 'conv1_kernal_size': 4, 'conv1_filters': 128, 'conv2_activation': 'tanh', 'conv2_kernal_size': 3, 'dense1_activation': 'tanh', 'dense1_filters': 32, 'dropout': 0.24388552837006705, 'dropout1': 0.2339869343152106, 'dropout2': 0.15239959970940184, 'dropout3': 0.23114677100545816, 'optimizer': 'Adam', 'learning_rate': 0.023549062057632502}. Best is trial 2 with value: 5.262175559997559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.414863586425781\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 551s 314ms/step - loss: 18.2651 - val_loss: 17.4648\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 530s 305ms/step - loss: 13.7089 - val_loss: 17.1768\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 536s 309ms/step - loss: 13.0875 - val_loss: 16.5114\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 537s 309ms/step - loss: 12.6084 - val_loss: 15.1691\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 537s 309ms/step - loss: 12.1849 - val_loss: 14.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 17:36:58,085]\u001b[0m Trial 5 finished with value: 14.709196090698242 and parameters: {'conv1_activation': 'relu', 'conv1_kernal_size': 2, 'conv1_filters': 128, 'conv2_activation': 'relu', 'conv2_kernal_size': 3, 'dense1_activation': 'relu', 'dense1_filters': 64, 'dropout': 0.29747031828362225, 'dropout1': 0.27438956728485125, 'dropout2': 0.23246832955701627, 'dropout3': 0.284303783937842, 'optimizer': 'Adam', 'learning_rate': 3.0951297051597176e-05}. Best is trial 2 with value: 5.262175559997559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.709196090698242\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 514s 293ms/step - loss: 23.5506 - val_loss: 15.0237\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 513s 295ms/step - loss: 14.2582 - val_loss: 14.5280\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 509s 293ms/step - loss: 13.7353 - val_loss: 14.1981\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 509s 293ms/step - loss: 13.4275 - val_loss: 14.0145\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 508s 293ms/step - loss: 13.2194 - val_loss: 13.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 18:19:55,271]\u001b[0m Trial 6 finished with value: 13.934127807617188 and parameters: {'conv1_activation': 'tanh', 'conv1_kernal_size': 3, 'conv1_filters': 32, 'conv2_activation': 'relu', 'conv2_kernal_size': 3, 'dense1_activation': 'tanh', 'dense1_filters': 16, 'dropout': 0.23734796951289494, 'dropout1': 0.22722773832474186, 'dropout2': 0.2214243990711678, 'dropout3': 0.29548491517208475, 'optimizer': 'RMSprop', 'learning_rate': 1.1696320810261748e-05}. Best is trial 2 with value: 5.262175559997559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.934127807617188\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 516s 294ms/step - loss: 13.8734 - val_loss: 14.4388\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 504s 290ms/step - loss: 11.4489 - val_loss: 12.3377\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 504s 290ms/step - loss: 9.7833 - val_loss: 10.7716\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 506s 291ms/step - loss: 8.5828 - val_loss: 9.3366\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 505s 291ms/step - loss: 7.5328 - val_loss: 8.5912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 19:02:34,563]\u001b[0m Trial 7 finished with value: 8.59115219116211 and parameters: {'conv1_activation': 'relu', 'conv1_kernal_size': 4, 'conv1_filters': 32, 'conv2_activation': 'relu', 'conv2_kernal_size': 4, 'dense1_activation': 'relu', 'dense1_filters': 32, 'dropout': 0.2376578003760425, 'dropout1': 0.21318774028985096, 'dropout2': 0.2410417312745997, 'dropout3': 0.2936370552020956, 'optimizer': 'Adam', 'learning_rate': 0.00039238005106890275}. Best is trial 2 with value: 5.262175559997559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.59115219116211\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 511s 291ms/step - loss: 15.0748 - val_loss: 13.9692\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 498s 287ms/step - loss: 12.4827 - val_loss: 12.8095\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 499s 287ms/step - loss: 11.6191 - val_loss: 12.3526\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 501s 288ms/step - loss: 10.8760 - val_loss: 11.6964\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 500s 288ms/step - loss: 10.2165 - val_loss: 10.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 19:44:45,708]\u001b[0m Trial 8 finished with value: 10.374730110168457 and parameters: {'conv1_activation': 'relu', 'conv1_kernal_size': 3, 'conv1_filters': 16, 'conv2_activation': 'tanh', 'conv2_kernal_size': 2, 'dense1_activation': 'relu', 'dense1_filters': 64, 'dropout': 0.19523811712859238, 'dropout1': 0.2817981489223422, 'dropout2': 0.1892199189940514, 'dropout3': 0.1543085468240067, 'optimizer': 'Adam', 'learning_rate': 0.00012024157737004158}. Best is trial 2 with value: 5.262175559997559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.374730110168457\n",
      "Epoch 1/5\n",
      "1737/1737 [==============================] - 531s 302ms/step - loss: 13.2044 - val_loss: 11.1193\n",
      "Epoch 2/5\n",
      "1737/1737 [==============================] - 515s 297ms/step - loss: 9.4412 - val_loss: 7.6272\n",
      "Epoch 3/5\n",
      "1737/1737 [==============================] - 515s 297ms/step - loss: 6.3865 - val_loss: 5.0394\n",
      "Epoch 4/5\n",
      "1737/1737 [==============================] - 515s 297ms/step - loss: 4.5058 - val_loss: 4.1139\n",
      "Epoch 5/5\n",
      "1737/1737 [==============================] - 515s 297ms/step - loss: 3.5270 - val_loss: 3.3352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-21 20:28:22,077]\u001b[0m Trial 9 finished with value: 3.33522367477417 and parameters: {'conv1_activation': 'relu', 'conv1_kernal_size': 2, 'conv1_filters': 64, 'conv2_activation': 'relu', 'conv2_kernal_size': 2, 'dense1_activation': 'tanh', 'dense1_filters': 128, 'dropout': 0.165444182763684, 'dropout1': 0.2929540339456813, 'dropout2': 0.1903758346041926, 'dropout3': 0.2652413191938886, 'optimizer': 'Adam', 'learning_rate': 0.0021336185815240276}. Best is trial 9 with value: 3.33522367477417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33522367477417\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "TRIALS = 50\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(train_ds,\n",
    "              validation_data=validation_ds,\n",
    "              epochs=EPOCHS)\n",
    "    score = model.evaluate(validation_ds, verbose=0)\n",
    "    print(score)\n",
    "    return score # loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=TRIALS)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Loss: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf175d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
